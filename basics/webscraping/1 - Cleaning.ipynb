{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a dummy dataset\n",
        "np.random.seed(0)\n",
        "dummy_data = {\n",
        "    'Feature1': np.random.normal(100, 10, 100).tolist() + [np.nan, 200],  # Normally distributed with an outlier\n",
        "    'Feature2': np.random.randint(0, 100, 102).tolist(),  # Random integers\n",
        "    'Category': ['A', 'B', 'C', 'D'] * 25 + [np.nan, 'A'],  # Categorical with some missing values\n",
        "    'Target': np.random.choice([0, 1], 102).tolist()  # Binary target variable\n",
        "}\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "df_dummy = pd.DataFrame(dummy_data)\n",
        "\n",
        "# Display the first few rows of the dummy dataset\n",
        "print(df_dummy.head())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "     Feature1  Feature2 Category  Target\n0  117.640523        32        A       1\n1  104.001572        70        B       1\n2  109.787380        85        C       0\n3  122.408932        31        D       1\n4  118.675580        13        A       0\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1757243843199
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values with the mean for numeric columns\n",
        "df_filled = df_dummy.fillna(df_dummy.mean())\n",
        "\n",
        "# Fill missing categorical data with the mode (most frequent value)\n",
        "df_filled['Category'].fillna(df_filled['Category'].mode()[0], inplace=True)\n",
        "\n",
        "print(df_filled.isnull().sum())  # Verify that there are no missing values"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipykernel_41181/1756322250.py:2: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n  df_filled = df_dummy.fillna(df_dummy.mean())\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1757243856239
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "# Calculate Z-scores for numerical features\n",
        "z_scores = np.abs(stats.zscore(df_filled.select_dtypes(include=[np.number])))\n",
        "\n",
        "# Remove rows with any Z-scores greater than 3 (commonly used threshold for outliers)\n",
        "df_no_outliers = df_filled[(z_scores < 3).all(axis=1)]\n",
        "\n",
        "print(df_no_outliers.describe())  # Verify that outliers have been removed"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "         Feature1    Feature2      Target\ncount  101.000000  101.000000  101.000000\nmean   100.607824   46.029703    0.534653\nstd     10.079298   27.147175    0.501285\nmin     74.470102    0.000000    0.000000\n25%     93.656779   28.000000    0.000000\n50%    101.216750   41.000000    1.000000\n75%    107.290906   69.000000    1.000000\nmax    122.697546   97.000000    1.000000\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1757243865592
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Scale numeric features using StandardScaler (Z-score normalization)\n",
        "scaler = StandardScaler()\n",
        "df_no_outliers[df_no_outliers.select_dtypes(include=[np.number]).columns] = scaler.fit_transform(df_no_outliers.select_dtypes(include=[np.number]))\n",
        "\n",
        "print(df_no_outliers.head())  # Verify that the data has been scaled"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipykernel_41181/2948938403.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_no_outliers[df_no_outliers.select_dtypes(include=[np.number]).columns] = scaler.fit_transform(df_no_outliers.select_dtypes(include=[np.number]))\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1757243876408
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode the categorical feature\n",
        "df_encoded = pd.get_dummies(df_no_outliers, columns=['Category'])\n",
        "\n",
        "print(df_encoded.head())  # Verify that the categorical variable has been encoded"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "   Feature1  Feature2    Target  Category_A  Category_B  Category_C  \\\n0  1.698298 -0.519379  0.932936           1           0           0   \n1  0.338384  0.887380  0.932936           0           1           0   \n2  0.915276  1.442679 -1.071884           0           0           1   \n3  2.173747 -0.556399  0.932936           0           0           0   \n4  1.801501 -1.222759 -1.071884           1           0           0   \n\n   Category_D  \n0           0  \n1           0  \n2           0  \n3           1  \n4           0  \n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1757243885439
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the preprocessed DataFrame to a CSV file\n",
        "df_encoded.to_csv('preprocessed_dummy_data.csv', index=False)\n",
        "\n",
        "print('Preprocessed data saved as preprocessed_dummy_data.csv')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Preprocessed data saved as preprocessed_dummy_data.csv\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1757243909639
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.18",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}